{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ujrbc1Bwsy1t"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sieq7Q-zo4yS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UBXdfwBImHzK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 드라이브 마운트해서 해당 네이버 리뷰데이터 가져오기"
      ],
      "metadata": {
        "id": "2sb7h5zTqDoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jndJejQK-tlK",
        "outputId": "81ca5f36-a16b-4af7-cccc-22e967eddd33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        rate                                               text\n",
              "0          5                                            배공빠르고 굿\n",
              "1          2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2          5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3          2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4          5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ\n",
              "...      ...                                                ...\n",
              "199995     2                                    장마라그런가!!! 달지않아요\n",
              "199996     5  다이슨 케이스 구매했어요 다이슨 슈퍼소닉 드라이기 케이스 구매했어요가격 괜찮고 배송...\n",
              "199997     5                    로드샾에서 사는것보다 세배 저렴하네요 ㅜㅜ 자주이용할께요\n",
              "199998     5                                      넘이쁘고 쎄련되보이네요~\n",
              "199999     5   아직 사용해보지도않았고 다른 제품을 써본적이없어서 잘 모르겠지만 ㅎㅎ 배송은 빨랐습니다\n",
              "\n",
              "[200000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bfe58bd-9570-4030-a28a-dbdfe3bbcb34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>2</td>\n",
              "      <td>장마라그런가!!! 달지않아요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>5</td>\n",
              "      <td>다이슨 케이스 구매했어요 다이슨 슈퍼소닉 드라이기 케이스 구매했어요가격 괜찮고 배송...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>5</td>\n",
              "      <td>로드샾에서 사는것보다 세배 저렴하네요 ㅜㅜ 자주이용할께요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>5</td>\n",
              "      <td>넘이쁘고 쎄련되보이네요~</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>5</td>\n",
              "      <td>아직 사용해보지도않았고 다른 제품을 써본적이없어서 잘 모르겠지만 ㅎㅎ 배송은 빨랐습니다</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bfe58bd-9570-4030-a28a-dbdfe3bbcb34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bfe58bd-9570-4030-a28a-dbdfe3bbcb34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bfe58bd-9570-4030-a28a-dbdfe3bbcb34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_table('/content/drive/MyDrive/corpus-master/corpus-master/sentiment/naver_shopping.txt',header = None) #데이터 불러오기\n",
        "df.columns = ['rate','text'] #데이터의 칼럼명 지정\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ti-naFjooSvs",
        "outputId": "13f18dba-06b5-4427-e4ca-48f2c05ce53b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rate                                               text\n",
              "0     5                                            배공빠르고 굿\n",
              "1     2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2     5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3     2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4     5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c312bc7-f494-4290-8850-089de80d20dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c312bc7-f494-4290-8850-089de80d20dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c312bc7-f494-4290-8850-089de80d20dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c312bc7-f494-4290-8850-089de80d20dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리\n"
      ],
      "metadata": {
        "id": "uNR62AGPCrEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값은 딱히 없다\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZs0zYFoCnC0",
        "outputId": "0b01f427-51bb-4a29-c0bf-08df8decdc9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rate    0\n",
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복값도 없다\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjq-N98_Cv4S",
        "outputId": "eebec361-8bb4-4ad3-d126-fad21138de5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리를 위한 krwordrank다운로드 해서 전처리하기"
      ],
      "metadata": {
        "id": "zFU4SCFzqIaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install krwordrank"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCdTuMM9oYq5",
        "outputId": "40e0cbb4-b5ad-4472-818a-4f0acc16ac92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting krwordrank\n",
            "  Downloading krwordrank-1.0.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from krwordrank) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from krwordrank) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.8/dist-packages (from krwordrank) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->krwordrank) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->krwordrank) (1.2.0)\n",
            "Installing collected packages: krwordrank\n",
            "Successfully installed krwordrank-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리를 하는데 위에 리뷰를 보면 ㅎㅎ처럼 특정 은어?? 같은 것들을 제거하는 역할임"
      ],
      "metadata": {
        "id": "xdQdva5Hqbem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from krwordrank.hangle import normalize\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x : normalize(x,english=True,number=True))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "029MItIxoWKv",
        "outputId": "c0ab0187-cd37-4485-b0e8-06e92d8e1ce4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rate                                               text\n",
              "0     5                                            배공빠르고 굿\n",
              "1     2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2     5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다 바느질이 조금 엉...\n",
              "3     2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다 전화...\n",
              "4     5                      민트색상 예뻐요 옆 손잡이는 거는 용도로도 사용되네요"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f026e342-8fd8-4e0f-9982-cb10a026acc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다 바느질이 조금 엉...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다 전화...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요 옆 손잡이는 거는 용도로도 사용되네요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f026e342-8fd8-4e0f-9982-cb10a026acc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f026e342-8fd8-4e0f-9982-cb10a026acc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f026e342-8fd8-4e0f-9982-cb10a026acc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# konlp로 감성 분석 코드"
      ],
      "metadata": {
        "id": "qBdlT0Xgom9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy #다운로드하기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA_0dG-oooqj",
        "outputId": "be1ae8da-6960-4652-826b-d49c47ae2364"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 679 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 먼저 학습과 시험데이터로 split하기\n",
        "# Okt()클래스 생성하기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "\n",
        "dataset_train, dataset_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=34)\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "FcY8q0EeorIa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zzFC9VW1os3g",
        "outputId": "c26e7b81-309d-4388-c454-bf751645547f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        rate                                               text\n",
              "50608      2  베개유목민인데 복구력이 넘좋다해서 삿지만 너무좋아서 높게느껴질 정도에요 평소 낮은베...\n",
              "76017      2  역시 저렴한 이유가 있네요 가격에 비해 너무 많은걸 바랬나봐요 딱 가격값하는 엄청 ...\n",
              "152093     2                      제품은 만족하는데 배송이 한진택배라 엄청 오래걸렸어요\n",
              "95204      1  이건 뭐 쓰던거 파는건가요 뚜껑이 새것처럼 잠금장치가 없네요 물건은 다 샛는지 터졋...\n",
              "181587     1  신은지 3주만에 밑창 떨어져서 구두방에 만원주고 수선했는데 어차피 금방 또 떨어진다..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21d23eab-a547-41a1-8c07-715775329665\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50608</th>\n",
              "      <td>2</td>\n",
              "      <td>베개유목민인데 복구력이 넘좋다해서 삿지만 너무좋아서 높게느껴질 정도에요 평소 낮은베...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76017</th>\n",
              "      <td>2</td>\n",
              "      <td>역시 저렴한 이유가 있네요 가격에 비해 너무 많은걸 바랬나봐요 딱 가격값하는 엄청 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152093</th>\n",
              "      <td>2</td>\n",
              "      <td>제품은 만족하는데 배송이 한진택배라 엄청 오래걸렸어요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95204</th>\n",
              "      <td>1</td>\n",
              "      <td>이건 뭐 쓰던거 파는건가요 뚜껑이 새것처럼 잠금장치가 없네요 물건은 다 샛는지 터졋...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181587</th>\n",
              "      <td>1</td>\n",
              "      <td>신은지 3주만에 밑창 떨어져서 구두방에 만원주고 수선했는데 어차피 금방 또 떨어진다...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21d23eab-a547-41a1-8c07-715775329665')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21d23eab-a547-41a1-8c07-715775329665 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21d23eab-a547-41a1-8c07-715775329665');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라벨은 1,2,4,5로 평점으로 5가 제일 좋은 평점임을 의미한다"
      ],
      "metadata": {
        "id": "NKS05uR1rpAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df['rate'].unique() #라벨데이터 종류 확인"
      ],
      "metadata": {
        "id": "m31cz7PAovE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 쓰기위해서 데이터를 리스트 형태로 바꿔주기\n",
        "\n",
        "dataset_train = dataset_train.values.tolist()\n",
        "dataset_test = dataset_test.values.tolist()"
      ],
      "metadata": {
        "id": "CaU7bgG7rvy_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCNthRM6sFnD",
        "outputId": "14215c9f-3914-448d-c44b-7698ad5140b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2,\n",
              "  '베개유목민인데 복구력이 넘좋다해서 삿지만 너무좋아서 높게느껴질 정도에요 평소 낮은베개를 선호해서 자고일어나면 어깨나 목이아프고 푹 잠을 못잔느낌'],\n",
              " [2, '역시 저렴한 이유가 있네요 가격에 비해 너무 많은걸 바랬나봐요 딱 가격값하는 엄청 얇은 재질의 상품이에요']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 아래코드는 토큰화해서 하나의 파일로 만드는 코드인데 이게 시간이 걸려서 만들어서 이미 파일을 만들어서 마운트하였다면 바로 그냥 실행됨"
      ],
      "metadata": {
        "id": "ujrbc1Bwsy1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 제가 올린 test_docs.json과 train_docs.json을 세션장소에 업로드를 하면 바로 실행됩니다!!"
      ],
      "metadata": {
        "id": "pWpPNS_ds-9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "# 리뷰를 토큰화하기 이때 토큰화하면서 품사도 정해진다.\n",
        "# 이때 기존에 올린 test_docs와 train_docs를 세션장소에 업로드 하면 바로 실행됨 (안하면 엄청 오래걸림)\n",
        "\n",
        "def tokenize(doc):\n",
        "    return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]\n",
        "\n",
        "if os.path.isfile('train_docs.json'):\n",
        "    with open('train_docs.json') as f:\n",
        "        train_docs = json.load(f)\n",
        "    with open('test_docs.json') as f:\n",
        "        test_docs = json.load(f)\n",
        "else:\n",
        "    train_docs = [(tokenize(row[1]), row[0]) for row in dataset_train]\n",
        "    test_docs = [(tokenize(row[1]), row[0]) for row in dataset_test]\n",
        "    # JSON 파일로 저장\n",
        "    with open('train_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
        "        json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
        "    with open('test_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
        "        json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
        "\n",
        "pprint(train_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpiY16KRsQca",
        "outputId": "95b79122-474d-4c7c-87f8-2981c747c889"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['베개/Noun',\n",
            "  '유목민/Noun',\n",
            "  '인데/Josa',\n",
            "  '복구/Noun',\n",
            "  '력/Suffix',\n",
            "  '이/Josa',\n",
            "  '넘다/Verb',\n",
            "  '좋다/Adjective',\n",
            "  '다해/Noun',\n",
            "  '서/Josa',\n",
            "  '삿/Noun',\n",
            "  '지만/Josa',\n",
            "  '너무/Adverb',\n",
            "  '좋다/Adjective',\n",
            "  '높다/Adjective',\n",
            "  '느껴지다/Verb',\n",
            "  '정도/Noun',\n",
            "  '에요/Josa',\n",
            "  '평소/Noun',\n",
            "  '낮다/Adjective',\n",
            "  '베개/Noun',\n",
            "  '를/Josa',\n",
            "  '선호/Noun',\n",
            "  '하다/Verb',\n",
            "  '자고/Noun',\n",
            "  '일어나다/Verb',\n",
            "  '어깨/Noun',\n",
            "  '나/Josa',\n",
            "  '목/Noun',\n",
            "  '이/Josa',\n",
            "  '아프다/Adjective',\n",
            "  '푹/Noun',\n",
            "  '잠/Noun',\n",
            "  '을/Josa',\n",
            "  '못자다/Verb',\n",
            "  '느낌/Noun'],\n",
            " 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train데이터의 토큰 개수 확인하기\n",
        "\n",
        "tokens = [t for d in train_docs for t in d[0]]\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQlwAQ5ut28g",
        "outputId": "558fd8c3-5229-42c1-c5e9-7b04c1b9ac75"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2266473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "text = nltk.Text(tokens, name='NMSC')\n",
        "\n",
        "# 전체 토큰의 개수\n",
        "print(len(text.tokens))\n",
        "\n",
        "# 중복을 제외한 토큰의 개수\n",
        "print(len(set(text.tokens)))            \n",
        "\n",
        "# 출현 빈도가 높은 상위 토큰 10개\n",
        "pprint(text.vocab().most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4IU5Hflt5lz",
        "outputId": "115b5ef7-2750-401c-eec3-2c3a949c9bcd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2266473\n",
            "38147\n",
            "[('하다/Verb', 78131),\n",
            " ('이/Josa', 54095),\n",
            " ('좋다/Adjective', 48787),\n",
            " ('도/Josa', 39088),\n",
            " ('에/Josa', 38327),\n",
            " ('가/Josa', 37461),\n",
            " ('너무/Adverb', 23529),\n",
            " ('배송/Noun', 22801),\n",
            " ('은/Josa', 20095),\n",
            " ('있다/Adjective', 17928)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가장 많이 사용된 토큰 10000개만 사용해서 분석에 사용하기\n",
        "이때 시간이 많이 걸렸습니다\n"
      ],
      "metadata": {
        "id": "Mh2sm22JuqhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10000개하였을떄 30분이상걸림 소모ram 17\n",
        "# 이 코드가 가장 오래 걸리니 이코드는 피클링된 모델을 쓰니 실행 안해도 됩니다\n",
        "\n",
        "selected_words = [f[0] for f in text.vocab().most_common(10000)]\n",
        "\n",
        "def term_frequency(doc):\n",
        "    return [doc.count(word) for word in selected_words]\n",
        "\n",
        "train_x = [term_frequency(d) for d, _ in train_docs]\n",
        "test_x = [term_frequency(d) for d, _ in test_docs]\n",
        "train_y = [c for _, c in train_docs]\n",
        "test_y = [c for _, c in test_docs]"
      ],
      "metadata": {
        "id": "_t21EFTbt73L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#float32로 바꿔주기\n",
        "#여기서도 ram많이 잡아먹음 ram 23\n",
        "#이코드도 실행 안해도 됩니다\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "x_train = np.asarray(train_x).astype('float32')\n",
        "x_test = np.asarray(test_x).astype('float32')\n",
        "\n",
        "y_train = np.asarray(train_y).astype('float32')\n",
        "y_test = np.asarray(test_y).astype('float32')"
      ],
      "metadata": {
        "id": "dM2EN_ibw10F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨데이터의 경우 원핫인코딩을 해주기\n",
        "#이코드도 실행 안해도 됩니다\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "Y_encoded = np_utils.to_categorical(y_train)\n",
        "Y_encoded_test = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "j_Xd6fttw5xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "#이코드도 실행 안해도 됩니다\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "             loss=losses.binary_crossentropy,\n",
        "             metrics=[metrics.binary_accuracy])\n",
        "\n",
        "model.fit(x_train, Y_encoded, epochs=10, batch_size=512)\n",
        "results = model.evaluate(x_test, Y_encoded_test)"
      ],
      "metadata": {
        "id": "baY_oLAew-13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795a6ac0-7d64-4ad7-efa8-06a427b70ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 16s 39ms/step - loss: 0.2767 - binary_accuracy: 0.8823\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2290 - binary_accuracy: 0.8964\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2218 - binary_accuracy: 0.9000\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2160 - binary_accuracy: 0.9033\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2102 - binary_accuracy: 0.9069\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2042 - binary_accuracy: 0.9108\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1980 - binary_accuracy: 0.9147\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1916 - binary_accuracy: 0.9181\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1849 - binary_accuracy: 0.9219\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1781 - binary_accuracy: 0.9255\n",
            "1250/1250 [==============================] - 3s 2ms/step - loss: 0.2667 - binary_accuracy: 0.8886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이코드도 실행 안해도 됩니다\n",
        "results = model.evaluate(x_test, Y_encoded_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFBOlujaCjJD",
        "outputId": "e51cd92c-1955-4652-b80b-0c0d9494dcba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 3s 2ms/step - loss: 0.2667 - binary_accuracy: 0.8886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 하는 함수 생성하기"
      ],
      "metadata": {
        "id": "6hg9YRGWCrOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#리뷰를 입력하면 리뷰의 평점을 예측하는 함수작성\n",
        "\n",
        "def predict_pos_neg(model,review):\n",
        "    token = tokenize(review)\n",
        "    tf = term_frequency(token)\n",
        "    data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n",
        "    \n",
        "    b = np.argmax(model.predict(data))\n",
        "\n",
        "\n",
        "    return b"
      ],
      "metadata": {
        "id": "mlimhZWSCof3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_pos_neg(model,'감사합니다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywz08mqCCuIP",
        "outputId": "221d62ae-9258-4dd7-b20e-bfe63f9ba5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_pos_neg(model,'아니 성능도 별로고 퀄리티도 안좋아요')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0bwbUehD-BH",
        "outputId": "7b4a9e68-3a94-44c6-c12a-f89fb887084f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "피클링을통해서 모델 저장"
      ],
      "metadata": {
        "id": "MZVPXuDj6_85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "\n",
        "#dumps를 통해서 잘 저장됨\n",
        "saved_model = pickle.dumps(model)"
      ],
      "metadata": {
        "id": "WqleaoRGxDl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model, '감성분석.pkl') "
      ],
      "metadata": {
        "id": "ZiGZWdNxx3hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5a0fcd-f105-415c-c1fb-68b85fef11cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['감성분석.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 피클링된 모델을 여기서 불러와서 테스트하면됩니다\n",
        "이때 토큰나이저가 있어야함\n",
        "위에서 함수정의는 실행되어야 합니다!!"
      ],
      "metadata": {
        "id": "foCgYa0K5BRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 시간이 오래걸린다고 한거는 실행안해도 됨 (단 위에서부터 나머지는 실행을 해야합니다)"
      ],
      "metadata": {
        "id": "Ts0XdqIk6NAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#다시 피클링된거를 가져오기\n",
        "import joblib\n",
        "\n",
        "test_model = joblib.load('감성분석.pkl') "
      ],
      "metadata": {
        "id": "Oy8Gl2aqCHsK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#얘는 위의 tokens와 text가 선언되야 합니다 (위쪽에 코드있어요)\n",
        "\n",
        "selected_words = [f[0] for f in text.vocab().most_common(10000)]"
      ],
      "metadata": {
        "id": "-W9Wl34256md"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def term_frequency(doc):\n",
        "    return [doc.count(word) for word in selected_words]"
      ],
      "metadata": {
        "id": "RuZ1qcpW5v4c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_pos_neg(test_model,'튼튼하고 좋아요!!')) # 잘 되는 것을 확인!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYO2RYxeCP3v",
        "outputId": "254d5b1d-d20d-4844-e939-b769db3fb70f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_pos_neg(test_model,'좋아요 만족합니다 헝 만족합니다 튼튼하고 포장도 좋아요 튼튼하게 와요 아쉬운 점은')) # 잘 되는 것을 확인!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwepkhND9Mt5",
        "outputId": "ce2e1cdf-8686-45ee-8ef7-454dc4c41800"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 14ms/step\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lstm모델로 리뷰 생성하기"
      ],
      "metadata": {
        "id": "4CkTApmgEvgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "fcTbERwyEy-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "BSNZiPTQFKHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#위의 리뷰데이터를 사용\n",
        "#이 모델의 한계점 데이터는 많은데 이걸 일일히 다 인코딩을 하게되니 엄청나게 모델의 메모리 소모가 커서 5천개만 사용하였습니다 ㅠㅠ\n",
        "#메모리의 한계를 해결하는 것도 해결과제 ㅠㅠ\n",
        "\n",
        "df_half = df.iloc[:5000,:]"
      ],
      "metadata": {
        "id": "s0l6D5j2FPdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 값들을 리스트로 저장\n",
        "\n",
        "headline = []\n",
        "headline.extend(list(df_half.text.values)) \n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTK8PczkFgIT",
        "outputId": "1e262f23-edcd-4781-d33f-765eb64dce59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['배공빠르고 굿',\n",
              " '택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고',\n",
              " '아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다 바느질이 조금 엉성하긴 하지만 편하고 가성비 최고예요',\n",
              " '선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다 전화했더니 바로주신다했지만 배송도 누락되어있었네요 확인안하고 바로 선물했으면 큰일날뻔했네요 이렇게 배송이 오래걸렸으면 사는거 다시 생각했을거같아요 아쉽네요',\n",
              " '민트색상 예뻐요 옆 손잡이는 거는 용도로도 사용되네요']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjqaceQXFn6n",
        "outputId": "1f18cc70-07c7-4dfb-c91c-b56ac42586dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰 크기\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(headline)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nksDScxFpi9",
        "outputId": "b9764bce-a0e0-4961-91ec-d9202b26a967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 21120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "\n",
        "for sentence in headline:\n",
        "\n",
        "    # 각 샘플에 대한 정수 인코딩\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy15eC68F8Sc",
        "outputId": "d8b99d3c-fd35-4869-c5c0-e7c29ebf1069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4323, 186],\n",
              " [772, 4324],\n",
              " [772, 4324, 4325],\n",
              " [772, 4324, 4325, 4326],\n",
              " [772, 4324, 4325, 4326, 2346],\n",
              " [772, 4324, 4325, 4326, 2346, 4327],\n",
              " [1201, 654],\n",
              " [1201, 654, 13],\n",
              " [1201, 654, 13, 4328],\n",
              " [1201, 654, 13, 4328, 8],\n",
              " [1201, 654, 13, 4328, 8, 94]]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "for key, value in tokenizer.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "    index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci2j0_cUGBdM",
        "outputId": "99ac093f-5e3e-4580-d6f1-3a6cfd5bc7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : 없어\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWrCVbrCGHIO",
        "outputId": "7b3fdbb1-8078-43a3-f5b0-a1783e2f12c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#max_len로 패딩처리를 해주기\n",
        "\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDp1RVrdGKpc",
        "outputId": "a4f21973-afcf-489f-f81d-37338bd6124e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0 4323  186]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0  772 4324]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0  772 4324 4325]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#배열형태로 바꾸고 x와 y를 분리하기\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "cxAbjw7vGR-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#여기서 메모리 용량이 엄청나게 소모된다\n",
        "#vocab_size는 위에서 구한 토큰의 크기\n",
        "\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "I3fH_cxTGXg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sD6BBwEG9-M",
        "outputId": "0316ba7d-a6b4-40c0-a899-e4082b39f22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38706, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJRoCXpzHCAR",
        "outputId": "d3b20474-45b0-4173-c3ce-12df63e79ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38706, 21120)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 모델 학습하기"
      ],
      "metadata": {
        "id": "QCCKuvWhHLkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이것도 오래걸리니 이걸하고 피클링을 진행해서 다음에는 시간소모를 아끼자"
      ],
      "metadata": {
        "id": "Oj4NCy_QQJMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "\n",
        "\n",
        "embedding_dim = 10\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TcxkdV4HES7",
        "outputId": "9e0830ef-8923-4a75-b0c1-693c32f7c6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1210/1210 - 26s - loss: 9.6769 - accuracy: 0.0122 - 26s/epoch - 21ms/step\n",
            "Epoch 2/200\n",
            "1210/1210 - 11s - loss: 9.0935 - accuracy: 0.0123 - 11s/epoch - 9ms/step\n",
            "Epoch 3/200\n",
            "1210/1210 - 11s - loss: 8.7943 - accuracy: 0.0132 - 11s/epoch - 9ms/step\n",
            "Epoch 4/200\n",
            "1210/1210 - 11s - loss: 8.4589 - accuracy: 0.0151 - 11s/epoch - 9ms/step\n",
            "Epoch 5/200\n",
            "1210/1210 - 11s - loss: 8.0272 - accuracy: 0.0177 - 11s/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "1210/1210 - 11s - loss: 7.5355 - accuracy: 0.0198 - 11s/epoch - 9ms/step\n",
            "Epoch 7/200\n",
            "1210/1210 - 11s - loss: 7.0210 - accuracy: 0.0244 - 11s/epoch - 9ms/step\n",
            "Epoch 8/200\n",
            "1210/1210 - 11s - loss: 6.5182 - accuracy: 0.0342 - 11s/epoch - 9ms/step\n",
            "Epoch 9/200\n",
            "1210/1210 - 11s - loss: 6.0367 - accuracy: 0.0560 - 11s/epoch - 9ms/step\n",
            "Epoch 10/200\n",
            "1210/1210 - 11s - loss: 5.5853 - accuracy: 0.0965 - 11s/epoch - 9ms/step\n",
            "Epoch 11/200\n",
            "1210/1210 - 11s - loss: 5.1656 - accuracy: 0.1525 - 11s/epoch - 9ms/step\n",
            "Epoch 12/200\n",
            "1210/1210 - 11s - loss: 4.7695 - accuracy: 0.2163 - 11s/epoch - 9ms/step\n",
            "Epoch 13/200\n",
            "1210/1210 - 11s - loss: 4.4042 - accuracy: 0.2793 - 11s/epoch - 9ms/step\n",
            "Epoch 14/200\n",
            "1210/1210 - 11s - loss: 4.0719 - accuracy: 0.3282 - 11s/epoch - 9ms/step\n",
            "Epoch 15/200\n",
            "1210/1210 - 11s - loss: 3.7675 - accuracy: 0.3777 - 11s/epoch - 9ms/step\n",
            "Epoch 16/200\n",
            "1210/1210 - 11s - loss: 3.4991 - accuracy: 0.4152 - 11s/epoch - 9ms/step\n",
            "Epoch 17/200\n",
            "1210/1210 - 11s - loss: 3.2576 - accuracy: 0.4499 - 11s/epoch - 9ms/step\n",
            "Epoch 18/200\n",
            "1210/1210 - 11s - loss: 3.0429 - accuracy: 0.4839 - 11s/epoch - 9ms/step\n",
            "Epoch 19/200\n",
            "1210/1210 - 11s - loss: 2.8486 - accuracy: 0.5135 - 11s/epoch - 9ms/step\n",
            "Epoch 20/200\n",
            "1210/1210 - 11s - loss: 2.6706 - accuracy: 0.5412 - 11s/epoch - 9ms/step\n",
            "Epoch 21/200\n",
            "1210/1210 - 11s - loss: 2.5121 - accuracy: 0.5673 - 11s/epoch - 9ms/step\n",
            "Epoch 22/200\n",
            "1210/1210 - 11s - loss: 2.3621 - accuracy: 0.5909 - 11s/epoch - 9ms/step\n",
            "Epoch 23/200\n",
            "1210/1210 - 11s - loss: 2.2242 - accuracy: 0.6131 - 11s/epoch - 9ms/step\n",
            "Epoch 24/200\n",
            "1210/1210 - 11s - loss: 2.0985 - accuracy: 0.6350 - 11s/epoch - 9ms/step\n",
            "Epoch 25/200\n",
            "1210/1210 - 11s - loss: 1.9820 - accuracy: 0.6547 - 11s/epoch - 9ms/step\n",
            "Epoch 26/200\n",
            "1210/1210 - 11s - loss: 1.8667 - accuracy: 0.6717 - 11s/epoch - 9ms/step\n",
            "Epoch 27/200\n",
            "1210/1210 - 11s - loss: 1.7584 - accuracy: 0.6912 - 11s/epoch - 9ms/step\n",
            "Epoch 28/200\n",
            "1210/1210 - 11s - loss: 1.6631 - accuracy: 0.7073 - 11s/epoch - 9ms/step\n",
            "Epoch 29/200\n",
            "1210/1210 - 11s - loss: 1.5736 - accuracy: 0.7230 - 11s/epoch - 9ms/step\n",
            "Epoch 30/200\n",
            "1210/1210 - 11s - loss: 1.4851 - accuracy: 0.7376 - 11s/epoch - 9ms/step\n",
            "Epoch 31/200\n",
            "1210/1210 - 11s - loss: 1.3992 - accuracy: 0.7524 - 11s/epoch - 9ms/step\n",
            "Epoch 32/200\n",
            "1210/1210 - 11s - loss: 1.3237 - accuracy: 0.7665 - 11s/epoch - 9ms/step\n",
            "Epoch 33/200\n",
            "1210/1210 - 11s - loss: 1.2493 - accuracy: 0.7796 - 11s/epoch - 9ms/step\n",
            "Epoch 34/200\n",
            "1210/1210 - 11s - loss: 1.1823 - accuracy: 0.7918 - 11s/epoch - 9ms/step\n",
            "Epoch 35/200\n",
            "1210/1210 - 11s - loss: 1.1238 - accuracy: 0.8017 - 11s/epoch - 9ms/step\n",
            "Epoch 36/200\n",
            "1210/1210 - 11s - loss: 1.0580 - accuracy: 0.8125 - 11s/epoch - 9ms/step\n",
            "Epoch 37/200\n",
            "1210/1210 - 11s - loss: 0.9994 - accuracy: 0.8231 - 11s/epoch - 9ms/step\n",
            "Epoch 38/200\n",
            "1210/1210 - 11s - loss: 0.9534 - accuracy: 0.8321 - 11s/epoch - 9ms/step\n",
            "Epoch 39/200\n",
            "1210/1210 - 11s - loss: 0.9043 - accuracy: 0.8405 - 11s/epoch - 9ms/step\n",
            "Epoch 40/200\n",
            "1210/1210 - 11s - loss: 0.8564 - accuracy: 0.8492 - 11s/epoch - 9ms/step\n",
            "Epoch 41/200\n",
            "1210/1210 - 11s - loss: 0.8209 - accuracy: 0.8554 - 11s/epoch - 9ms/step\n",
            "Epoch 42/200\n",
            "1210/1210 - 11s - loss: 0.7703 - accuracy: 0.8635 - 11s/epoch - 9ms/step\n",
            "Epoch 43/200\n",
            "1210/1210 - 11s - loss: 0.7328 - accuracy: 0.8721 - 11s/epoch - 9ms/step\n",
            "Epoch 44/200\n",
            "1210/1210 - 11s - loss: 0.7008 - accuracy: 0.8759 - 11s/epoch - 9ms/step\n",
            "Epoch 45/200\n",
            "1210/1210 - 11s - loss: 0.6765 - accuracy: 0.8799 - 11s/epoch - 9ms/step\n",
            "Epoch 46/200\n",
            "1210/1210 - 11s - loss: 0.6490 - accuracy: 0.8848 - 11s/epoch - 9ms/step\n",
            "Epoch 47/200\n",
            "1210/1210 - 11s - loss: 0.6069 - accuracy: 0.8935 - 11s/epoch - 9ms/step\n",
            "Epoch 48/200\n",
            "1210/1210 - 11s - loss: 0.5833 - accuracy: 0.8963 - 11s/epoch - 9ms/step\n",
            "Epoch 49/200\n",
            "1210/1210 - 11s - loss: 0.5766 - accuracy: 0.8969 - 11s/epoch - 9ms/step\n",
            "Epoch 50/200\n",
            "1210/1210 - 11s - loss: 0.5487 - accuracy: 0.9009 - 11s/epoch - 9ms/step\n",
            "Epoch 51/200\n",
            "1210/1210 - 11s - loss: 0.5100 - accuracy: 0.9074 - 11s/epoch - 9ms/step\n",
            "Epoch 52/200\n",
            "1210/1210 - 11s - loss: 0.4956 - accuracy: 0.9095 - 11s/epoch - 9ms/step\n",
            "Epoch 53/200\n",
            "1210/1210 - 11s - loss: 0.5001 - accuracy: 0.9089 - 11s/epoch - 9ms/step\n",
            "Epoch 54/200\n",
            "1210/1210 - 11s - loss: 0.4672 - accuracy: 0.9143 - 11s/epoch - 9ms/step\n",
            "Epoch 55/200\n",
            "1210/1210 - 11s - loss: 0.4368 - accuracy: 0.9176 - 11s/epoch - 9ms/step\n",
            "Epoch 56/200\n",
            "1210/1210 - 11s - loss: 0.4462 - accuracy: 0.9159 - 11s/epoch - 9ms/step\n",
            "Epoch 57/200\n",
            "1210/1210 - 11s - loss: 0.4339 - accuracy: 0.9174 - 11s/epoch - 9ms/step\n",
            "Epoch 58/200\n",
            "1210/1210 - 11s - loss: 0.4166 - accuracy: 0.9193 - 11s/epoch - 9ms/step\n",
            "Epoch 59/200\n",
            "1210/1210 - 11s - loss: 0.4114 - accuracy: 0.9189 - 11s/epoch - 9ms/step\n",
            "Epoch 60/200\n",
            "1210/1210 - 11s - loss: 0.3985 - accuracy: 0.9217 - 11s/epoch - 9ms/step\n",
            "Epoch 61/200\n",
            "1210/1210 - 11s - loss: 0.3821 - accuracy: 0.9244 - 11s/epoch - 9ms/step\n",
            "Epoch 62/200\n",
            "1210/1210 - 11s - loss: 0.3696 - accuracy: 0.9255 - 11s/epoch - 9ms/step\n",
            "Epoch 63/200\n",
            "1210/1210 - 11s - loss: 0.3783 - accuracy: 0.9233 - 11s/epoch - 9ms/step\n",
            "Epoch 64/200\n",
            "1210/1210 - 11s - loss: 0.3628 - accuracy: 0.9262 - 11s/epoch - 9ms/step\n",
            "Epoch 65/200\n",
            "1210/1210 - 11s - loss: 0.3649 - accuracy: 0.9240 - 11s/epoch - 9ms/step\n",
            "Epoch 66/200\n",
            "1210/1210 - 11s - loss: 0.3499 - accuracy: 0.9270 - 11s/epoch - 9ms/step\n",
            "Epoch 67/200\n",
            "1210/1210 - 11s - loss: 0.3440 - accuracy: 0.9283 - 11s/epoch - 9ms/step\n",
            "Epoch 68/200\n",
            "1210/1210 - 11s - loss: 0.3307 - accuracy: 0.9294 - 11s/epoch - 9ms/step\n",
            "Epoch 69/200\n",
            "1210/1210 - 11s - loss: 0.3459 - accuracy: 0.9257 - 11s/epoch - 9ms/step\n",
            "Epoch 70/200\n",
            "1210/1210 - 11s - loss: 0.3337 - accuracy: 0.9275 - 11s/epoch - 9ms/step\n",
            "Epoch 71/200\n",
            "1210/1210 - 11s - loss: 0.3159 - accuracy: 0.9305 - 11s/epoch - 9ms/step\n",
            "Epoch 72/200\n",
            "1210/1210 - 11s - loss: 0.3142 - accuracy: 0.9299 - 11s/epoch - 9ms/step\n",
            "Epoch 73/200\n",
            "1210/1210 - 11s - loss: 0.3350 - accuracy: 0.9252 - 11s/epoch - 9ms/step\n",
            "Epoch 74/200\n",
            "1210/1210 - 11s - loss: 0.3113 - accuracy: 0.9299 - 11s/epoch - 9ms/step\n",
            "Epoch 75/200\n",
            "1210/1210 - 11s - loss: 0.2973 - accuracy: 0.9323 - 11s/epoch - 9ms/step\n",
            "Epoch 76/200\n",
            "1210/1210 - 11s - loss: 0.2960 - accuracy: 0.9314 - 11s/epoch - 9ms/step\n",
            "Epoch 77/200\n",
            "1210/1210 - 11s - loss: 0.3128 - accuracy: 0.9278 - 11s/epoch - 9ms/step\n",
            "Epoch 78/200\n",
            "1210/1210 - 11s - loss: 0.3180 - accuracy: 0.9267 - 11s/epoch - 9ms/step\n",
            "Epoch 79/200\n",
            "1210/1210 - 11s - loss: 0.2931 - accuracy: 0.9317 - 11s/epoch - 9ms/step\n",
            "Epoch 80/200\n",
            "1210/1210 - 11s - loss: 0.2832 - accuracy: 0.9326 - 11s/epoch - 9ms/step\n",
            "Epoch 81/200\n",
            "1210/1210 - 11s - loss: 0.2967 - accuracy: 0.9302 - 11s/epoch - 9ms/step\n",
            "Epoch 82/200\n",
            "1210/1210 - 11s - loss: 0.2951 - accuracy: 0.9307 - 11s/epoch - 9ms/step\n",
            "Epoch 83/200\n",
            "1210/1210 - 11s - loss: 0.3022 - accuracy: 0.9280 - 11s/epoch - 9ms/step\n",
            "Epoch 84/200\n",
            "1210/1210 - 11s - loss: 0.2871 - accuracy: 0.9312 - 11s/epoch - 9ms/step\n",
            "Epoch 85/200\n",
            "1210/1210 - 11s - loss: 0.2746 - accuracy: 0.9335 - 11s/epoch - 9ms/step\n",
            "Epoch 86/200\n",
            "1210/1210 - 11s - loss: 0.2819 - accuracy: 0.9316 - 11s/epoch - 9ms/step\n",
            "Epoch 87/200\n",
            "1210/1210 - 11s - loss: 0.2977 - accuracy: 0.9288 - 11s/epoch - 9ms/step\n",
            "Epoch 88/200\n",
            "1210/1210 - 11s - loss: 0.2851 - accuracy: 0.9310 - 11s/epoch - 9ms/step\n",
            "Epoch 89/200\n",
            "1210/1210 - 11s - loss: 0.2763 - accuracy: 0.9314 - 11s/epoch - 9ms/step\n",
            "Epoch 90/200\n",
            "1210/1210 - 11s - loss: 0.2885 - accuracy: 0.9296 - 11s/epoch - 9ms/step\n",
            "Epoch 91/200\n",
            "1210/1210 - 11s - loss: 0.2800 - accuracy: 0.9318 - 11s/epoch - 9ms/step\n",
            "Epoch 92/200\n",
            "1210/1210 - 11s - loss: 0.2673 - accuracy: 0.9329 - 11s/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "1210/1210 - 11s - loss: 0.2810 - accuracy: 0.9308 - 11s/epoch - 9ms/step\n",
            "Epoch 94/200\n",
            "1210/1210 - 11s - loss: 0.2955 - accuracy: 0.9282 - 11s/epoch - 9ms/step\n",
            "Epoch 95/200\n",
            "1210/1210 - 11s - loss: 0.2735 - accuracy: 0.9316 - 11s/epoch - 9ms/step\n",
            "Epoch 96/200\n",
            "1210/1210 - 11s - loss: 0.2696 - accuracy: 0.9319 - 11s/epoch - 9ms/step\n",
            "Epoch 97/200\n",
            "1210/1210 - 11s - loss: 0.2917 - accuracy: 0.9275 - 11s/epoch - 9ms/step\n",
            "Epoch 98/200\n",
            "1210/1210 - 11s - loss: 0.2704 - accuracy: 0.9316 - 11s/epoch - 9ms/step\n",
            "Epoch 99/200\n",
            "1210/1210 - 11s - loss: 0.2593 - accuracy: 0.9339 - 11s/epoch - 9ms/step\n",
            "Epoch 100/200\n",
            "1210/1210 - 11s - loss: 0.2698 - accuracy: 0.9309 - 11s/epoch - 9ms/step\n",
            "Epoch 101/200\n",
            "1210/1210 - 11s - loss: 0.3018 - accuracy: 0.9245 - 11s/epoch - 9ms/step\n",
            "Epoch 102/200\n",
            "1210/1210 - 11s - loss: 0.2902 - accuracy: 0.9267 - 11s/epoch - 9ms/step\n",
            "Epoch 103/200\n",
            "1210/1210 - 11s - loss: 0.2745 - accuracy: 0.9306 - 11s/epoch - 9ms/step\n",
            "Epoch 104/200\n",
            "1210/1210 - 11s - loss: 0.2576 - accuracy: 0.9336 - 11s/epoch - 9ms/step\n",
            "Epoch 105/200\n",
            "1210/1210 - 11s - loss: 0.2549 - accuracy: 0.9337 - 11s/epoch - 9ms/step\n",
            "Epoch 106/200\n",
            "1210/1210 - 11s - loss: 0.2706 - accuracy: 0.9303 - 11s/epoch - 9ms/step\n",
            "Epoch 107/200\n",
            "1210/1210 - 11s - loss: 0.2822 - accuracy: 0.9278 - 11s/epoch - 9ms/step\n",
            "Epoch 108/200\n",
            "1210/1210 - 11s - loss: 0.2726 - accuracy: 0.9302 - 11s/epoch - 9ms/step\n",
            "Epoch 109/200\n",
            "1210/1210 - 11s - loss: 0.2570 - accuracy: 0.9333 - 11s/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "1210/1210 - 11s - loss: 0.2550 - accuracy: 0.9333 - 11s/epoch - 9ms/step\n",
            "Epoch 111/200\n",
            "1210/1210 - 11s - loss: 0.2775 - accuracy: 0.9284 - 11s/epoch - 9ms/step\n",
            "Epoch 112/200\n",
            "1210/1210 - 11s - loss: 0.2847 - accuracy: 0.9263 - 11s/epoch - 9ms/step\n",
            "Epoch 113/200\n",
            "1210/1210 - 11s - loss: 0.2688 - accuracy: 0.9303 - 11s/epoch - 9ms/step\n",
            "Epoch 114/200\n",
            "1210/1210 - 11s - loss: 0.2552 - accuracy: 0.9321 - 11s/epoch - 9ms/step\n",
            "Epoch 115/200\n",
            "1210/1210 - 11s - loss: 0.2595 - accuracy: 0.9322 - 11s/epoch - 9ms/step\n",
            "Epoch 116/200\n",
            "1210/1210 - 11s - loss: 0.2583 - accuracy: 0.9316 - 11s/epoch - 9ms/step\n",
            "Epoch 117/200\n",
            "1210/1210 - 11s - loss: 0.2735 - accuracy: 0.9292 - 11s/epoch - 9ms/step\n",
            "Epoch 118/200\n",
            "1210/1210 - 11s - loss: 0.2641 - accuracy: 0.9306 - 11s/epoch - 9ms/step\n",
            "Epoch 119/200\n",
            "1210/1210 - 11s - loss: 0.2568 - accuracy: 0.9325 - 11s/epoch - 9ms/step\n",
            "Epoch 120/200\n",
            "1210/1210 - 11s - loss: 0.2534 - accuracy: 0.9327 - 11s/epoch - 9ms/step\n",
            "Epoch 121/200\n",
            "1210/1210 - 11s - loss: 0.2560 - accuracy: 0.9322 - 11s/epoch - 9ms/step\n",
            "Epoch 122/200\n",
            "1210/1210 - 11s - loss: 0.2668 - accuracy: 0.9306 - 11s/epoch - 9ms/step\n",
            "Epoch 123/200\n",
            "1210/1210 - 11s - loss: 0.2597 - accuracy: 0.9317 - 11s/epoch - 9ms/step\n",
            "Epoch 124/200\n",
            "1210/1210 - 11s - loss: 0.2554 - accuracy: 0.9319 - 11s/epoch - 9ms/step\n",
            "Epoch 125/200\n",
            "1210/1210 - 11s - loss: 0.2640 - accuracy: 0.9303 - 11s/epoch - 9ms/step\n",
            "Epoch 126/200\n",
            "1210/1210 - 11s - loss: 0.2602 - accuracy: 0.9308 - 11s/epoch - 9ms/step\n",
            "Epoch 127/200\n",
            "1210/1210 - 11s - loss: 0.2605 - accuracy: 0.9309 - 11s/epoch - 9ms/step\n",
            "Epoch 128/200\n",
            "1210/1210 - 11s - loss: 0.2561 - accuracy: 0.9316 - 11s/epoch - 9ms/step\n",
            "Epoch 129/200\n",
            "1210/1210 - 11s - loss: 0.2620 - accuracy: 0.9300 - 11s/epoch - 9ms/step\n",
            "Epoch 130/200\n",
            "1210/1210 - 11s - loss: 0.2590 - accuracy: 0.9305 - 11s/epoch - 9ms/step\n",
            "Epoch 131/200\n",
            "1210/1210 - 11s - loss: 0.2560 - accuracy: 0.9317 - 11s/epoch - 9ms/step\n",
            "Epoch 132/200\n",
            "1210/1210 - 11s - loss: 0.2606 - accuracy: 0.9310 - 11s/epoch - 9ms/step\n",
            "Epoch 133/200\n",
            "1210/1210 - 11s - loss: 0.2565 - accuracy: 0.9307 - 11s/epoch - 9ms/step\n",
            "Epoch 134/200\n",
            "1210/1210 - 11s - loss: 0.2578 - accuracy: 0.9309 - 11s/epoch - 9ms/step\n",
            "Epoch 135/200\n",
            "1210/1210 - 11s - loss: 0.2559 - accuracy: 0.9315 - 11s/epoch - 9ms/step\n",
            "Epoch 136/200\n",
            "1210/1210 - 11s - loss: 0.2514 - accuracy: 0.9319 - 11s/epoch - 9ms/step\n",
            "Epoch 137/200\n",
            "1210/1210 - 11s - loss: 0.2496 - accuracy: 0.9326 - 11s/epoch - 9ms/step\n",
            "Epoch 138/200\n",
            "1210/1210 - 11s - loss: 0.2456 - accuracy: 0.9333 - 11s/epoch - 9ms/step\n",
            "Epoch 139/200\n",
            "1210/1210 - 11s - loss: 0.2630 - accuracy: 0.9292 - 11s/epoch - 9ms/step\n",
            "Epoch 140/200\n",
            "1210/1210 - 11s - loss: 0.2669 - accuracy: 0.9275 - 11s/epoch - 9ms/step\n",
            "Epoch 141/200\n",
            "1210/1210 - 11s - loss: 0.2586 - accuracy: 0.9307 - 11s/epoch - 9ms/step\n",
            "Epoch 142/200\n",
            "1210/1210 - 11s - loss: 0.2554 - accuracy: 0.9314 - 11s/epoch - 9ms/step\n",
            "Epoch 143/200\n",
            "1210/1210 - 11s - loss: 0.2441 - accuracy: 0.9338 - 11s/epoch - 9ms/step\n",
            "Epoch 144/200\n",
            "1210/1210 - 11s - loss: 0.2464 - accuracy: 0.9335 - 11s/epoch - 9ms/step\n",
            "Epoch 145/200\n",
            "1210/1210 - 11s - loss: 0.2590 - accuracy: 0.9310 - 11s/epoch - 9ms/step\n",
            "Epoch 146/200\n",
            "1210/1210 - 11s - loss: 0.2567 - accuracy: 0.9307 - 11s/epoch - 9ms/step\n",
            "Epoch 147/200\n",
            "1210/1210 - 11s - loss: 0.2469 - accuracy: 0.9328 - 11s/epoch - 9ms/step\n",
            "Epoch 148/200\n",
            "1210/1210 - 11s - loss: 0.2662 - accuracy: 0.9294 - 11s/epoch - 9ms/step\n",
            "Epoch 149/200\n",
            "1210/1210 - 11s - loss: 0.2548 - accuracy: 0.9303 - 11s/epoch - 9ms/step\n",
            "Epoch 150/200\n",
            "1210/1210 - 11s - loss: 0.2427 - accuracy: 0.9337 - 11s/epoch - 9ms/step\n",
            "Epoch 151/200\n",
            "1210/1210 - 11s - loss: 0.2423 - accuracy: 0.9330 - 11s/epoch - 9ms/step\n",
            "Epoch 152/200\n",
            "1210/1210 - 11s - loss: 0.2549 - accuracy: 0.9308 - 11s/epoch - 9ms/step\n",
            "Epoch 153/200\n",
            "1210/1210 - 11s - loss: 0.2564 - accuracy: 0.9297 - 11s/epoch - 9ms/step\n",
            "Epoch 154/200\n",
            "1210/1210 - 11s - loss: 0.2530 - accuracy: 0.9311 - 11s/epoch - 9ms/step\n",
            "Epoch 155/200\n",
            "1210/1210 - 11s - loss: 0.2457 - accuracy: 0.9322 - 11s/epoch - 9ms/step\n",
            "Epoch 156/200\n",
            "1210/1210 - 11s - loss: 0.2502 - accuracy: 0.9318 - 11s/epoch - 9ms/step\n",
            "Epoch 157/200\n",
            "1210/1210 - 11s - loss: 0.2619 - accuracy: 0.9293 - 11s/epoch - 9ms/step\n",
            "Epoch 158/200\n",
            "1210/1210 - 11s - loss: 0.2532 - accuracy: 0.9311 - 11s/epoch - 9ms/step\n",
            "Epoch 159/200\n",
            "1210/1210 - 11s - loss: 0.2481 - accuracy: 0.9323 - 11s/epoch - 9ms/step\n",
            "Epoch 160/200\n",
            "1210/1210 - 11s - loss: 0.2466 - accuracy: 0.9329 - 11s/epoch - 9ms/step\n",
            "Epoch 161/200\n",
            "1210/1210 - 11s - loss: 0.2699 - accuracy: 0.9268 - 11s/epoch - 9ms/step\n",
            "Epoch 162/200\n",
            "1210/1210 - 11s - loss: 0.2634 - accuracy: 0.9283 - 11s/epoch - 9ms/step\n",
            "Epoch 163/200\n",
            "1210/1210 - 11s - loss: 0.2531 - accuracy: 0.9304 - 11s/epoch - 9ms/step\n",
            "Epoch 164/200\n",
            "1210/1210 - 11s - loss: 0.2499 - accuracy: 0.9320 - 11s/epoch - 9ms/step\n",
            "Epoch 165/200\n",
            "1210/1210 - 11s - loss: 0.2646 - accuracy: 0.9278 - 11s/epoch - 9ms/step\n",
            "Epoch 166/200\n",
            "1210/1210 - 11s - loss: 0.2446 - accuracy: 0.9327 - 11s/epoch - 9ms/step\n",
            "Epoch 167/200\n",
            "1210/1210 - 11s - loss: 0.2490 - accuracy: 0.9322 - 11s/epoch - 9ms/step\n",
            "Epoch 168/200\n",
            "1210/1210 - 11s - loss: 0.2752 - accuracy: 0.9252 - 11s/epoch - 9ms/step\n",
            "Epoch 169/200\n",
            "1210/1210 - 11s - loss: 0.2592 - accuracy: 0.9295 - 11s/epoch - 9ms/step\n",
            "Epoch 170/200\n",
            "1210/1210 - 11s - loss: 0.3122 - accuracy: 0.9182 - 11s/epoch - 9ms/step\n",
            "Epoch 171/200\n",
            "1210/1210 - 11s - loss: 0.3091 - accuracy: 0.9180 - 11s/epoch - 9ms/step\n",
            "Epoch 172/200\n",
            "1210/1210 - 11s - loss: 0.2583 - accuracy: 0.9298 - 11s/epoch - 9ms/step\n",
            "Epoch 173/200\n",
            "1210/1210 - 11s - loss: 0.2675 - accuracy: 0.9284 - 11s/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "1210/1210 - 11s - loss: 0.2509 - accuracy: 0.9316 - 11s/epoch - 9ms/step\n",
            "Epoch 175/200\n",
            "1210/1210 - 11s - loss: 0.2395 - accuracy: 0.9333 - 11s/epoch - 9ms/step\n",
            "Epoch 176/200\n",
            "1210/1210 - 11s - loss: 0.2443 - accuracy: 0.9327 - 11s/epoch - 9ms/step\n",
            "Epoch 177/200\n",
            "1210/1210 - 11s - loss: 0.2476 - accuracy: 0.9315 - 11s/epoch - 9ms/step\n",
            "Epoch 178/200\n",
            "1210/1210 - 11s - loss: 0.2591 - accuracy: 0.9301 - 11s/epoch - 9ms/step\n",
            "Epoch 179/200\n",
            "1210/1210 - 11s - loss: 0.2630 - accuracy: 0.9283 - 11s/epoch - 9ms/step\n",
            "Epoch 180/200\n",
            "1210/1210 - 11s - loss: 0.2506 - accuracy: 0.9304 - 11s/epoch - 9ms/step\n",
            "Epoch 181/200\n",
            "1210/1210 - 11s - loss: 0.2481 - accuracy: 0.9321 - 11s/epoch - 9ms/step\n",
            "Epoch 182/200\n",
            "1210/1210 - 11s - loss: 0.2640 - accuracy: 0.9275 - 11s/epoch - 9ms/step\n",
            "Epoch 183/200\n",
            "1210/1210 - 11s - loss: 0.2456 - accuracy: 0.9322 - 11s/epoch - 9ms/step\n",
            "Epoch 184/200\n",
            "1210/1210 - 11s - loss: 0.2485 - accuracy: 0.9319 - 11s/epoch - 9ms/step\n",
            "Epoch 185/200\n",
            "1210/1210 - 11s - loss: 0.2435 - accuracy: 0.9320 - 11s/epoch - 9ms/step\n",
            "Epoch 186/200\n",
            "1210/1210 - 11s - loss: 0.2495 - accuracy: 0.9308 - 11s/epoch - 9ms/step\n",
            "Epoch 187/200\n",
            "1210/1210 - 11s - loss: 0.2578 - accuracy: 0.9291 - 11s/epoch - 9ms/step\n",
            "Epoch 188/200\n",
            "1210/1210 - 11s - loss: 0.2492 - accuracy: 0.9312 - 11s/epoch - 9ms/step\n",
            "Epoch 189/200\n",
            "1210/1210 - 11s - loss: 0.2477 - accuracy: 0.9319 - 11s/epoch - 9ms/step\n",
            "Epoch 190/200\n",
            "1210/1210 - 11s - loss: 0.2419 - accuracy: 0.9329 - 11s/epoch - 9ms/step\n",
            "Epoch 191/200\n",
            "1210/1210 - 11s - loss: 0.2631 - accuracy: 0.9282 - 11s/epoch - 9ms/step\n",
            "Epoch 192/200\n",
            "1210/1210 - 11s - loss: 0.2497 - accuracy: 0.9314 - 11s/epoch - 9ms/step\n",
            "Epoch 193/200\n",
            "1210/1210 - 11s - loss: 0.2464 - accuracy: 0.9313 - 11s/epoch - 9ms/step\n",
            "Epoch 194/200\n",
            "1210/1210 - 11s - loss: 0.2456 - accuracy: 0.9314 - 11s/epoch - 9ms/step\n",
            "Epoch 195/200\n",
            "1210/1210 - 11s - loss: 0.2530 - accuracy: 0.9309 - 11s/epoch - 9ms/step\n",
            "Epoch 196/200\n",
            "1210/1210 - 11s - loss: 0.2536 - accuracy: 0.9304 - 11s/epoch - 9ms/step\n",
            "Epoch 197/200\n",
            "1210/1210 - 11s - loss: 0.2454 - accuracy: 0.9321 - 11s/epoch - 9ms/step\n",
            "Epoch 198/200\n",
            "1210/1210 - 11s - loss: 0.2501 - accuracy: 0.9313 - 11s/epoch - 9ms/step\n",
            "Epoch 199/200\n",
            "1210/1210 - 11s - loss: 0.2708 - accuracy: 0.9260 - 11s/epoch - 9ms/step\n",
            "Epoch 200/200\n",
            "1210/1210 - 11s - loss: 0.2719 - accuracy: 0.9261 - 11s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd4d560a670>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 생성된 모델을 바탕으로 단어를 입력하면 문장을 만들어내는 함수 구현하기"
      ],
      "metadata": {
        "id": "Tbf4I3psLXWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "lmFb9wZRLcj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 해보기"
      ],
      "metadata": {
        "id": "kF_HmEKQQR1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '별로', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4GBQ2EWLiMV",
        "outputId": "665f0ae0-c8b7-4934-aef1-675128160c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "별로 잘 지지해 주지는 못하는거 같아요 믿고 하면서 뒤로 값어치할줄알았는데 예쁘고\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '좋아요',10 ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkA1fHdzQVhz",
        "outputId": "26ad8048-b607-4267-dca5-ca0c8261ec8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "좋아요 만족합니다 헝 만족합니다 튼튼하고 포장도 좋아요 튼튼하게 와요 아쉬운 점은\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dumps를 통해서 잘 저장됨\n",
        "saved_model = pickle.dumps(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0nzD0-cLnoV",
        "outputId": "1dbd780a-2cfb-435d-8537-b817f282a584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model, '문장생성.pkl') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyRrbp-yLq-a",
        "outputId": "317df83b-713f-4ffb-8800-17adb4747b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['문장생성.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이부분에서 피클링된것을 불러와서 테스트하면 됩니다!!"
      ],
      "metadata": {
        "id": "N4K8K9OB7NbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = joblib.load('문장생성.pkl') "
      ],
      "metadata": {
        "id": "n1JwzpT-LstW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list()\n",
        "\n",
        "for sentence in headline:\n",
        "\n",
        "    # 각 샘플에 대한 정수 인코딩\n",
        "    encoded = tokenizer.texts_to_sequences([sentence])[0] \n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18xs1aSB7yzZ",
        "outputId": "e65cbfde-5601-4b2e-cba4-764f3e9ace36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4323, 186],\n",
              " [772, 4324],\n",
              " [772, 4324, 4325],\n",
              " [772, 4324, 4325, 4326],\n",
              " [772, 4324, 4325, 4326, 2346],\n",
              " [772, 4324, 4325, 4326, 2346, 4327],\n",
              " [1201, 654],\n",
              " [1201, 654, 13],\n",
              " [1201, 654, 13, 4328],\n",
              " [1201, 654, 13, 4328, 8],\n",
              " [1201, 654, 13, 4328, 8, 94]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VdLQ4Df7q1M",
        "outputId": "2fea123d-2455-41d5-e3da-e20c65e7f014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(test_model, tokenizer, '맜있어요', 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq545EwCQnYU",
        "outputId": "c8470222-5f4d-4c21-9cfd-48564d262743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "맜있어요 우알롱에서 다양한 사이즈 너무 너무 배송도 좋아요 너무 좋아요 용량이 넘 힘들어요 여기서 디자인 색깔도 훨씬 만족스럽습니다 것 듭니다 조금\n"
          ]
        }
      ]
    }
  ]
}